{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(df, train_perc = 0.8):\n",
    "    df['train'] = np.random.rand(len(df)) < train_perc\n",
    "    train = df[df.train == 1]\n",
    "    test = df[df.train == 0]\n",
    "    split_data ={'train': train, 'test': test}\n",
    "    return split_data\n",
    "\n",
    "def cleanstr(somestring):\n",
    "    rx = re.compile('\\W+')\n",
    "    return rx.sub(' ', somestring).strip()\n",
    "\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who talks how much ! \n",
      "\n",
      "Rachel      9319\n",
      "Ross        9112\n",
      "Chandler    8499\n",
      "Monica      8441\n",
      "Joey        8210\n",
      "Phoebe      7504\n",
      "Name: Author, dtype: int64\n",
      "Total rows   : 61563\n",
      "Training set : 49309\n",
      "Test Set     : 12254\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('friends-transcripts corpus.txt',delimiter='\\t')\n",
    "\n",
    "#Clean Reading Corpus\n",
    "df = df[2:]\n",
    "df.drop(\"Season & Episode\", axis=1 , inplace=True)\n",
    "\n",
    "#Correcting Dtypes\n",
    "df.Season = pd.to_numeric(df.Season , errors='raise')\n",
    "df.Episode = pd.to_numeric(df.Episode, errors='coerce')\n",
    "df.Episode = df.Episode.replace(np.nan , 17)\n",
    "df.Title = df.Title.astype(str)\n",
    "df.Quote = df.Quote.astype(str)\n",
    "df.Author = df.Author.astype(str)\n",
    "\n",
    "#c1 = df.Quote[df.Author.str.contains(\"Rachel\")]\n",
    "#c2 = df.Quote[df.Author.str.contains(\"Ross\")]\n",
    "#c3 = df.Quote[df.Author.str.contains(\"Chandler\")]\n",
    "#c4 = df.Quote[df.Author.str.contains(\"Monica\")]\n",
    "#c5 = df.Quote[df.Author.str.contains(\"Joey\")]\n",
    "#c6 = df.Quote[df.Author.str.contains(\"Phoebe\")]\n",
    "#print len(c1), len(c2), len(c3), len(c4), len(c5), len(c6)\n",
    "\n",
    "#Preliminary Analysis\n",
    "print (\"Who talks how much ! \\n\")\n",
    "print (df.Author.value_counts()[0:6])\n",
    "\n",
    "#Sampling Dataset\n",
    "\n",
    "#dict of Dataframes\n",
    "Dataset = split_data(df , train_perc=0.8)\n",
    "print (\"Total rows   :\" , df.shape[0])\n",
    "print (\"Training set :\" , len(Dataset['train']))\n",
    "print (\"Test Set     :\" , len(Dataset['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 412171\n",
      "total chars: 66\n",
      "nb sequences: 137377\n",
      "Vectorization...\n",
      "Attempting to load model from h5py\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "137377/137377 [==============================] - 908s - loss: 2.0020   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"there never was a library. i mean there \"\n",
      "there never was a library. i mean there and i gonna get and the beally and i mave and the paren that i was the pare that it a donna me and the and and the bet to get that i was and i mave the see in the bees the bet and and i mave and and and and the that and and and and i mave to you got and and the bet and that and and a don't me and and and and the have to and it that is a mave the and i mave the bet to the bees the bast and the bet \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"there never was a library. i mean there \"\n",
      "there never was a library. i mean there se and i cand it soully deat that it was a mave mignt same tare and i don't gust but i gond abe thing to and and and i don��t know a dowe mane and i mave that this the gonns on the ract and it a don't and and that me.  weal.  i am.  ok, you got a dist it talk thing me me so.  hey, is a bat that we an the cason.  ah, and i mean, i mave the dannat me it fon and in the resed that was a don't me thing\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"there never was a library. i mean there \"\n",
      "there never was a library. i mean there the olp and yeah wiukrelping, and.  that was i move kands, it'a it stan, ame theing so wase ghe taik �e, she i the ting hay bepned it athould ovevl on. gut!  beadong the lo:keraht goen way sot llacled. recwin!  yeah., 9maale domeen my caris?  you know?  se\", you wall ablling, muckey year, juss inallgmer it!..oie.. wals arouly  fot 2es, thi-ghy candes.  i-all migh?.!  you know a    ok shms caf thev\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"there never was a library. i mean there \"\n",
      "there never was a library. i mean there patico qaly mangptaryudingg ont one chappbet, nut thob! i 9ie��ve my hangrretarc, conifg ss taken sou walk scieul!eliendimedlh breint, i'mint that,ysux would that seshsase.. bocal. but... ghat stigeaing.!  kyow.  you lotk!  se:, me .  alace.  ackuld, boq.  i allmy, ina-bascenmanylome. an the kyvwong. ow��s lukey. i'm, shing hat se on ite. im, se er. wrathe beces efcarnnt anut you peanly.y!!  nea! \n",
      "Model and weights saved to directory\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "137377/137377 [==============================] - 888s - loss: 1.8929   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" wrong?   wh-what's going on?  no, i arr\"\n",
      " wrong?   wh-what's going on?  no, i arragind and i the biget the back to the back to the beat the back to me a beat the bees it to got a meat the back the bight the pare the beally the back to hell the beat the bet the beally mack to me sore the the back to me i that thing to be a preat the back to the bight the back it the bight the back of the care the bight the bet a lat the the call the back the bay right a little the the biget the\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" wrong?   wh-what's going on?  no, i arr\"\n",
      " wrong?   wh-what's going on?  no, i arryall that the out like to made the caus then the sume this is a care to be to the firing sore ah.  ah, i this gore the batthing to dodn��t the some to maly all in the ppopest it this this it me up to mist acture the this thould so to tellers the care af aut the toollare the losto to the porly me and the allist fart to sor a littlith the eace a latter that the mast!   ah- she hand the betille the c\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" wrong?   wh-what's going on?  no, i arr\"\n",
      " wrong?   wh-what's going on?  no, i arrant and.  f.e!  car, that��s jvencanet in this is of gey!  abe so rling?  oh liftiteass was diall �in3. rathy hape i i wound their.   how. that's gont. ipmesbe to ged up an what like liss warlilay det this it��s.   fither bettleine freacen you somling, fndap?   i llisice chees yar really reaully.  o, fursseally kit to you malies ey.  that ah,  'kan, i'm nobre: what? i's not touh, i i qitid e, we h\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" wrong?   wh-what's going on?  no, i arr\"\n",
      " wrong?   wh-what's going on?  no, i arrsa all?  somald wifh braind in tha.  or nas.   not ik��s ut radeit me asat,ibostnu7werstwet was ont we tals afsiat \"harlay 7a-cand wo lide i eveapen  tomtes thet- liec? huh up of you sar go? srallysheh.�ich-mammser, i'm tllve��ve any  goo.  no!  hoy... char sbeow!   liogiraippy macppy a liaterit? a fually. foed you meacel anacuffor the didir!  acaus.   bele��lhec��sl! no won��t-me.   okay, i-efpai\n",
      "Model and weights saved to directory\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "137377/137377 [==============================] - 908s - loss: 1.7899   \n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"the mans right, thats what i had wit\"\n",
      "the mans right, thats what i had with the back to the page and i the the the back to the back to me the back to me the back to the better the back to the better the back to the bet the cares and the says and the bet and the back to the bet and the can the sore and and the kidnat the bet the bick and it the the the says and i think i want to the back to the cantery and the care the care and and the kids and the back the back to me th\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"the mans right, thats what i had wit\"\n",
      "the mans right, thats what i had with the parelt me finy, the sors to wether the book the cacken wo be there you do a got me and chen a see his another and the hat look about the called a lett any don��t all somether bick and when he doon the wast somether the back come of you thook to stolaed.   that's gonna he she with the know when a see in the bet to me about this out.  that's this ally right, i hean i think to the and of a she�\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"the mans right, thats what i had wit\"\n",
      "the mans right, thats what i had with to okey it not scombone.  oh any why didnem a wer anyo hen the machon.  hey goon how-you��re belw the gays6, just, that��s ig'tely, i��m gosn then we hould cattey thut ittencel5 so, betpersice, you pingy her ando that��s lousn��s fricket about?   hey do and this bunf. god no the mongey onp.  sme��s.  ik.   okay, you guttery!��  what��ve rikizss at cume.  hay kyow she laktif there't doon��t nothi\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"the mans right, thats what i had wit\"\n",
      "the mans right, thats what i had witlepd. on!  ovay.! fool.  that.!  ooh pireess abmungivameame. amout! meaply .o  you!   ok, comay, huh, that's-yuky reaty.  yackne theys didnay. just upgected. it��know you conn tofeich on 'ssearla.  listedtrrabey eache ingine, like oleaye?  yei!!  cool!  ah, yok, you bebot in�egtispenth mains for, was.. that is thid ifdoingfphand that yourgunt! ighaal! �pkeapen, by ming, y5uhmenilreohing. a praand \n",
      "Model and weights saved to directory\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "  8576/137377 [>.............................] - ETA: 833s - loss: 1.7572"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f3602d3d09eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iteration'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mstart_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/irtza/Downloads/enter/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    403\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/irtza/Downloads/enter/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/irtza/Downloads/enter/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    782\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/irtza/Downloads/enter/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[0mupdated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/irtza/Downloads/enter/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;33m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/irtza/Downloads/enter/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 511\u001b[1;33m                            feed_dict_string)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/irtza/Downloads/enter/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 564\u001b[1;33m                            target_list)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/irtza/Downloads/enter/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/irtza/Downloads/enter/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Takes one Hour to Train!\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "friend = \"Ross\"\n",
    "train=False\n",
    "save=True\n",
    "\n",
    "\n",
    "text = ' '.join(Dataset['train'].Quote[Dataset['train'].Author == friend].tolist())\n",
    "text = text.lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = set(text)\n",
    "\n",
    "if not chars:\n",
    "    print (\"Invalid friends character, type: Ross Rachel Phoebe Chandler Monica or Joey\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "\n",
    "# build the model: 2 stacked LSTM\n",
    "if train:\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(512, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(len(chars)))\n",
    "    model.add(Activation('softmax'))\n",
    "else:\n",
    "    print (\"Attempting to load model from h5py\")\n",
    "    model = model_from_json(open(friend+'.json').read())\n",
    "    model.load_weights(friend+'.h5')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "\n",
    "for iteration in range(1, 40):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=1)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "    if save:\n",
    "        json_string = model.to_json()\n",
    "        open(friend+'.json', 'w').write(json_string)\n",
    "        model.save_weights(friend+'.h5' , overwrite = True)\n",
    "        print (\"Model and weights saved to directory\")\n",
    "\n",
    "    else:\n",
    "        print (\"model not saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generateSentencesLike(\"Phoebe\" , train=True , save=True)\n",
    "#Takes one Hour to Train!\n",
    "\n",
    "#Rachel \n",
    "#Chandle \n",
    "#Phoebe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generateSentencesLike(\"Rachel\" , train=True , save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = model_from_json(open(friend+'.json').read())\n",
    "#model.load_weights(friend+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137377/137377 [==============================] - 283s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.063252645727458"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "#model.fit(X, y, batch_size=128, nb_epoch=1)\n",
    "#model.evaluate(X,y, batch_size=128 )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 512)\n",
      "(512, 512)\n",
      "(512,)\n",
      "(66, 512)\n",
      "(512, 512)\n",
      "(512,)\n",
      "(66, 512)\n",
      "(512, 512)\n",
      "(512,)\n",
      "(66, 512)\n",
      "(512, 512)\n",
      "(512,)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "#for i in range(0,15):\n",
    "#    print (model.get_weights()[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
